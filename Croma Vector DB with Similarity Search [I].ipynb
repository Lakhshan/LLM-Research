{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937bbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc219b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x1b9fc1 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1b9b79 for key /ToUnicode\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"C:\\\\Users\\\\Lakhshan\\\\Desktop\\\\College\\\\Intern\\\\Ref GPT\\\\Milvus.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3d4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4cda6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lakhshan\\Desktop\\College\\Intern\\Ref GPT\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5becaf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(texts, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e27abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Milvus?\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30b173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing so, Milvus ensures that results in previous rounds will not\n",
      "appear in the current round. After that, the new results are merged\n",
      "with the partial results obtained in earlier rounds. Milvus processes\n",
      "the query in a round-by-round fashion until a sufficient number of\n",
      "results are collected.\n",
      "Supporting multi-GPU devices. Faiss [ 3] supports multiple\n",
      "GPU devices since they are usually found in modern servers. But\n",
      "Faiss needs to declare all the GPU devices in advance during com-\n",
      "pilation time. That means if the Faiss codebase is compiled using a\n",
      "server with ùëêGPUs, then the software binary can only be running\n",
      "in a server that has at least ùëêGPUs.\n",
      "Milvus overcomes this limitation by allowing users to select any\n",
      "number of GPU devices during runtime (instead of compilation\n",
      "time). As a result, once the Milvus codebase is compiled into a\n",
      "software binary, it can run at any server. Under the hood, Milvus\n",
      "introduces a segment-based scheduling that assigns segment-based\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "357b5181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='doing so, Milvus ensures that results in previous rounds will not\\nappear in the current round. After that, the new results are merged\\nwith the partial results obtained in earlier rounds. Milvus processes\\nthe query in a round-by-round fashion until a sufficient number of\\nresults are collected.\\nSupporting multi-GPU devices. Faiss [ 3] supports multiple\\nGPU devices since they are usually found in modern servers. But\\nFaiss needs to declare all the GPU devices in advance during com-\\npilation time. That means if the Faiss codebase is compiled using a\\nserver with ùëêGPUs, then the software binary can only be running\\nin a server that has at least ùëêGPUs.\\nMilvus overcomes this limitation by allowing users to select any\\nnumber of GPU devices during runtime (instead of compilation\\ntime). As a result, once the Milvus codebase is compiled into a\\nsoftware binary, it can run at any server. Under the hood, Milvus\\nintroduces a segment-based scheduling that assigns segment-based', metadata={'source': 'C:\\\\Users\\\\Lakhshan\\\\Desktop\\\\College\\\\Intern\\\\Ref GPT\\\\Milvus.pdf', 'page': 5}),\n",
       " Document(page_content='data science and AI applications. It is a specialized system for\\nhigh-dimensional vectors following the design practice of one-size-\\nnot-fits-all [ 60] in contrast to generalizing relational databases to\\nsupport vectors. Milvus provides many application interfaces (in-\\ncluding SDKs in Python/Java/Go/C++ and RESTful APIs) that can\\nbe easily used by applications. Milvus is highly tuned for the het-\\nerogeneous computing architecture with modern CPUs and GPUs\\n(multiple GPU devices) for the best efficiency. It supports versatile\\nquery types such as vector similarity search with various similarityfunctions, attribute filtering, and multi-vector query processing.\\nIt provides different types of indexes (e.g., quantization-based in-\\ndexes [ 33,35] and graph-based indexes [ 20,49]) and develops an ex-\\ntensible interface to easily incorporate new indexes into the system.\\nMilvus manages dynamic vector data (e.g., insertions and deletions)', metadata={'source': 'C:\\\\Users\\\\Lakhshan\\\\Desktop\\\\College\\\\Intern\\\\Ref GPT\\\\Milvus.pdf', 'page': 1}),\n",
       " Document(page_content='though Milvus supports more indexes.\\nFigure 8 shows the results on IVF indexes (i.e., quantization-\\nbased indexes). Overall, Milvus (even CPU version) significantly\\noutperforms existing systems by up to two orders of magnitude\\nwhile keeping the similar recall. In particular, Milvus is 6.4 √ó‚àº27.0√ó\\nfaster than Vearch; 153.7 √ófaster than System B even if System B\\nruns on four nodes;114.7√ó‚àº 11.5√ófaster than System C even\\nif System C runs on two nodes; 1.3 √ó‚àº 2.1√ófaster than SPTAG\\n(tree-based index). But SPTAG cannot achieve very high recall (e.g.,\\n0.99) as Milvus does and also SPTAG takes 14 √ómore memory than\\nMilvus (17.88GB vs. 1.27GB).12The GPU version of Milvus is even\\nfaster since data can fit in the GPU memory in this setting. We\\nomit the results of System B on Deep10M since it only supports\\nthe Euclidean distance metric. We also omit the results of Vearch\\non GPU because there are multiple bugs in building indexes that', metadata={'source': 'C:\\\\Users\\\\Lakhshan\\\\Desktop\\\\College\\\\Intern\\\\Ref GPT\\\\Milvus.pdf', 'page': 9}),\n",
       " Document(page_content='Milvus: A Purpose-Built Vector Data Management System SIGMOD ‚Äô21, June 20‚Äì25, 2021, Virtual Event, China\\nfind for each query qùëñits top-ùëòsimilar vectors? In practice, users\\ncan submit batch queries so that ùëö‚â•1.\\nThis operation happens in finding the relevant buckets as well as\\nsearching within each relevant bucket. The original implementation\\nin Facebook Faiss [ 3], which Milvus is built on top of, is inefficient\\nbecause it incurs many CPU cache misses as explained below. Thus,\\nMilvus develops an optimized approach to significantly reduce data\\nmovement between main memory and CPU caches.\\nOriginal implementation in Facebook Faiss [3]. Faiss uses\\nthe OpenMP multi-threading to process queries in parallel. Each\\nthread is assigned to work on a single query at a time. The thread\\nis released (for next query) once the current task is finished. Each\\ntask compares qùëñwith all theùëõdata vectors and maintains a ùëò-sized\\nheap to store the results.', metadata={'source': 'C:\\\\Users\\\\Lakhshan\\\\Desktop\\\\College\\\\Intern\\\\Ref GPT\\\\Milvus.pdf', 'page': 4})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RefGPT",
   "language": "python",
   "name": "refgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
